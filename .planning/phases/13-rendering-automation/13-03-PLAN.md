---
phase: 13-rendering-automation
plan: 03
type: execute
---

<objective>
Add artifact management with R2 upload for rendered videos, thumbnails, subtitles, and chapters.

Purpose: Complete the render pipeline by uploading artifacts to R2 storage and cleaning up local files.

Output: Full artifact pipeline with cloud storage integration.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
**From Phase 13 Plan 2:**
- Render worker processes jobs and outputs to `/tmp/ruach-renders/`
- completeJob() currently stores local path (needs R2 URL)
- Worker marks job complete after render
- Ready for artifact upload integration

**From Phase 12:**
- Remotion renders MP4 video with captions and chapters
- Video includes burned-in captions, chapters, speaker labels
- Output is viewer-ready MP4

**Phase 13 Plan 3 Scope:**
- R2 upload service for video artifacts
- Thumbnail extraction from rendered video
- Subtitles export (VTT format)
- Chapters export (JSON format)
- Local file cleanup after upload
- Update completeJob with R2 URLs
- Error handling for upload failures

**Victory Condition:**
Job rendered → artifacts uploaded to R2 → URLs stored in database → local files cleaned up
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create R2 upload service</name>
  <files>ruach-ministries-backend/src/services/r2-upload.ts</files>
  <action>Create service to upload files to Cloudflare R2:

  ```typescript
  /**
   * Phase 13 Plan 3: R2 Upload Service
   *
   * Handles artifact uploads to Cloudflare R2 storage
   */

  import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
  import * as fs from 'fs/promises';
  import * as path from 'path';
  import { createReadStream } from 'fs';

  export interface UploadResult {
    success: boolean;
    url?: string;
    error?: string;
  }

  export default class R2Upload {
    private static client: S3Client | null = null;

    /**
     * Initialize R2 client
     */
    private static getClient(): S3Client {
      if (this.client) {
        return this.client;
      }

      const accountId = process.env.R2_ACCOUNT_ID;
      const accessKeyId = process.env.R2_ACCESS_KEY_ID;
      const secretAccessKey = process.env.R2_SECRET_ACCESS_KEY;

      if (!accountId || !accessKeyId || !secretAccessKey) {
        throw new Error('R2 credentials not configured');
      }

      this.client = new S3Client({
        region: 'auto',
        endpoint: `https://${accountId}.r2.cloudflarestorage.com`,
        credentials: {
          accessKeyId,
          secretAccessKey,
        },
      });

      return this.client;
    }

    /**
     * Upload file to R2
     *
     * @param localPath - Local file path
     * @param r2Key - R2 object key (path in bucket)
     * @param contentType - MIME type
     * @returns Upload result with public URL
     */
    static async uploadFile(
      localPath: string,
      r2Key: string,
      contentType: string
    ): Promise<UploadResult> {
      try {
        const client = this.getClient();
        const bucketName = process.env.R2_BUCKET_NAME;
        const publicDomain = process.env.R2_PUBLIC_DOMAIN;

        if (!bucketName) {
          throw new Error('R2_BUCKET_NAME not configured');
        }

        // Read file
        const fileBuffer = await fs.readFile(localPath);

        // Upload to R2
        await client.send(
          new PutObjectCommand({
            Bucket: bucketName,
            Key: r2Key,
            Body: fileBuffer,
            ContentType: contentType,
          })
        );

        // Build public URL
        const url = publicDomain
          ? `https://${publicDomain}/${r2Key}`
          : `https://${bucketName}.r2.cloudflarestorage.com/${r2Key}`;

        console.log(`[r2-upload] Uploaded ${r2Key} (${fileBuffer.length} bytes)`);

        return {
          success: true,
          url,
        };
      } catch (error: any) {
        console.error('[r2-upload] Upload failed:', error);
        return {
          success: false,
          error: error.message || 'Unknown upload error',
        };
      }
    }

    /**
     * Upload video render artifacts
     *
     * @param jobId - Render job ID
     * @param sessionId - Recording session ID
     * @param localVideoPath - Local video file path
     * @returns Object with R2 URLs for all artifacts
     */
    static async uploadRenderArtifacts(
      jobId: string,
      sessionId: string,
      localVideoPath: string
    ): Promise<{
      videoUrl?: string;
      thumbnailUrl?: string;
      error?: string;
    }> {
      try {
        // Upload video
        const videoKey = `renders/${sessionId}/${jobId}.mp4`;
        const videoResult = await this.uploadFile(localVideoPath, videoKey, 'video/mp4');

        if (!videoResult.success) {
          throw new Error(`Video upload failed: ${videoResult.error}`);
        }

        console.log(`[r2-upload] Render artifacts uploaded for job ${jobId}`);

        return {
          videoUrl: videoResult.url,
        };
      } catch (error: any) {
        console.error('[r2-upload] Artifact upload failed:', error);
        return {
          error: error.message || 'Unknown error',
        };
      }
    }
  }
  ```

  R2 Configuration:
  - Uses AWS S3 SDK (compatible with R2)
  - Environment variables: R2_ACCOUNT_ID, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY, R2_BUCKET_NAME
  - Optional: R2_PUBLIC_DOMAIN for custom domain URLs
  - Uploads to `renders/{sessionId}/{jobId}.mp4`

  Methods:
  - `uploadFile()` - Generic file upload
  - `uploadRenderArtifacts()` - Upload video and return URL
  </action>
  <verify>R2 upload service compiles, can upload files</verify>
  <done>R2 upload service ready for artifact uploads</done>
</task>

<task type="auto">
  <name>Task 2: Install AWS SDK for R2</name>
  <files>ruach-ministries-backend/package.json</files>
  <action>Install AWS SDK for S3 (R2 compatible):

  ```bash
  cd ruach-ministries-backend
  pnpm add @aws-sdk/client-s3
  ```

  The AWS S3 SDK is compatible with Cloudflare R2 and provides a standard interface for object storage.
  </action>
  <verify>AWS SDK installed in package.json</verify>
  <done>AWS SDK available for R2 uploads</done>
</task>

<task type="auto">
  <name>Task 3: Create thumbnail generator service</name>
  <files>ruach-ministries-backend/src/services/thumbnail-generator.ts</files>
  <action>Create service to extract thumbnail from video using ffmpeg:

  ```typescript
  /**
   * Phase 13 Plan 3: Thumbnail Generator
   *
   * Extracts thumbnail from rendered video using ffmpeg
   */

  import { exec } from 'child_process';
  import { promisify } from 'util';
  import * as path from 'path';
  import * as fs from 'fs/promises';

  const execAsync = promisify(exec);

  export interface ThumbnailResult {
    success: boolean;
    thumbnailPath?: string;
    error?: string;
  }

  export default class ThumbnailGenerator {
    /**
     * Generate thumbnail from video
     *
     * @param videoPath - Path to video file
     * @param outputPath - Path for thumbnail (optional, defaults to same dir as video)
     * @param timeOffset - Time offset in seconds to extract frame (default: 3)
     * @returns Thumbnail generation result
     */
    static async generateThumbnail(
      videoPath: string,
      outputPath?: string,
      timeOffset: number = 3
    ): Promise<ThumbnailResult> {
      try {
        // Generate output path if not provided
        if (!outputPath) {
          const dir = path.dirname(videoPath);
          const basename = path.basename(videoPath, path.extname(videoPath));
          outputPath = path.join(dir, `${basename}-thumb.jpg`);
        }

        // Ensure output directory exists
        const outputDir = path.dirname(outputPath);
        await fs.mkdir(outputDir, { recursive: true });

        // Extract frame using ffmpeg
        // -ss: seek to time offset
        // -i: input file
        // -vframes 1: extract one frame
        // -q:v 2: high quality JPEG (1-31, lower is better)
        const command = `ffmpeg -ss ${timeOffset} -i "${videoPath}" -vframes 1 -q:v 2 "${outputPath}" -y`;

        console.log('[thumbnail-generator] Extracting thumbnail from video');

        await execAsync(command, {
          timeout: 30000, // 30 second timeout
        });

        // Verify thumbnail exists
        try {
          await fs.access(outputPath);
        } catch {
          return {
            success: false,
            error: 'Thumbnail file not created',
          };
        }

        console.log(`[thumbnail-generator] Thumbnail created: ${outputPath}`);

        return {
          success: true,
          thumbnailPath: outputPath,
        };
      } catch (error: any) {
        console.error('[thumbnail-generator] Thumbnail generation failed:', error);
        return {
          success: false,
          error: error.message || 'Unknown error',
        };
      }
    }

    /**
     * Check if ffmpeg is installed
     */
    static async checkInstallation(): Promise<boolean> {
      try {
        await execAsync('ffmpeg -version');
        return true;
      } catch {
        console.error('[thumbnail-generator] ffmpeg not found');
        return false;
      }
    }
  }
  ```

  Thumbnail Generation:
  - Uses ffmpeg to extract frame at 3 seconds
  - High quality JPEG output
  - Saves to same directory as video with `-thumb.jpg` suffix
  - 30 second timeout
  </action>
  <verify>Thumbnail generator compiles, ffmpeg accessible</verify>
  <done>Thumbnail generator ready for use</done>
</task>

<task type="auto">
  <name>Task 4: Update render worker to upload artifacts</name>
  <files>ruach-ministries-backend/src/services/render-worker.ts</files>
  <action>Update processJob() to upload artifacts after render completes:

  Import R2Upload and ThumbnailGenerator at top:
  ```typescript
  import R2Upload from './r2-upload';
  import ThumbnailGenerator from './thumbnail-generator';
  ```

  Replace the "TODO Plan 3" section (after renderResult.success check) with:
  ```typescript
      if (!renderResult.success) {
        throw new Error(renderResult.error || 'Render failed');
      }

      console.log(`[render-worker] Render completed, uploading artifacts for ${renderJobId}`);

      // Update progress
      await renderJobService.transitionStatus(renderJobId, 'processing', {
        progress: 0.85,
      });

      // Generate thumbnail
      const thumbnailResult = await ThumbnailGenerator.generateThumbnail(
        outputPath,
        undefined, // Auto-generate path
        3 // Extract frame at 3 seconds
      );

      // Update progress
      await renderJobService.transitionStatus(renderJobId, 'processing', {
        progress: 0.9,
      });

      // Upload artifacts to R2
      const uploadResult = await R2Upload.uploadRenderArtifacts(
        renderJobId,
        sessionId,
        outputPath
      );

      if (uploadResult.error) {
        throw new Error(`Artifact upload failed: ${uploadResult.error}`);
      }

      // Upload thumbnail if generated
      let thumbnailUrl: string | undefined;
      if (thumbnailResult.success && thumbnailResult.thumbnailPath) {
        const thumbnailKey = `renders/${sessionId}/${renderJobId}-thumb.jpg`;
        const thumbnailUpload = await R2Upload.uploadFile(
          thumbnailResult.thumbnailPath,
          thumbnailKey,
          'image/jpeg'
        );

        if (thumbnailUpload.success) {
          thumbnailUrl = thumbnailUpload.url;
        }
      }

      // Update progress
      await renderJobService.transitionStatus(renderJobId, 'processing', {
        progress: 0.95,
      });

      // Get video metadata (duration, size, resolution)
      const stats = await fs.stat(outputPath);
      const fileSizeBytes = stats.size;

      // Complete job with R2 URLs
      await renderJobService.completeJob(renderJobId, {
        outputVideoUrl: uploadResult.videoUrl!,
        outputThumbnailUrl: thumbnailUrl,
        durationMs: renderResult.durationMs,
        fileSizeBytes,
      });

      // Cleanup local files
      try {
        await fs.unlink(outputPath);
        if (thumbnailResult.thumbnailPath) {
          await fs.unlink(thumbnailResult.thumbnailPath);
        }
        console.log(`[render-worker] Cleaned up local files for ${renderJobId}`);
      } catch (cleanupError) {
        console.warn(`[render-worker] Failed to cleanup local files:`, cleanupError);
        // Don't fail job if cleanup fails
      }

      console.log(`[render-worker] Job ${renderJobId} completed successfully`);
  ```

  Add fs import at top:
  ```typescript
  import * as fs from 'fs/promises';
  ```

  Updated Flow:
  1. Render video (0-85%)
  2. Generate thumbnail (85%)
  3. Upload video to R2 (90%)
  4. Upload thumbnail to R2 (90%)
  5. Get video metadata (95%)
  6. Complete job with R2 URLs (100%)
  7. Cleanup local files
  </action>
  <verify>Worker uploads artifacts and cleans up local files</verify>
  <done>Complete artifact pipeline with R2 upload</done>
</task>

<task type="auto">
  <name>Task 5: Add R2 environment variables documentation</name>
  <files>ruach-ministries-backend/.env.example</files>
  <action>Add R2 configuration to .env.example:

  Check if .env.example exists. If not, create it. Add these lines:

  ```bash
  # Cloudflare R2 Storage (for render artifacts)
  R2_ACCOUNT_ID=your-account-id
  R2_ACCESS_KEY_ID=your-access-key
  R2_SECRET_ACCESS_KEY=your-secret-key
  R2_BUCKET_NAME=ruach-renders
  R2_PUBLIC_DOMAIN=renders.ruachstudios.com  # Optional: custom domain for public URLs
  ```

  Documentation:
  - Account ID from Cloudflare dashboard
  - Access keys from R2 API tokens
  - Bucket must be created in R2 console
  - Public domain requires CNAME setup
  </action>
  <verify>.env.example updated with R2 configuration</verify>
  <done>Environment variables documented</done>
</task>

<task type="auto">
  <name>Task 6: Update render job service artifact fields</name>
  <files>ruach-ministries-backend/src/api/render-job/services/render-job-service.ts</files>
  <action>Update completeJob() to accept fileSizeBytes:

  Update RenderArtifacts interface:
  ```typescript
  export interface RenderArtifacts {
    outputVideoUrl: string;
    outputThumbnailUrl?: string;
    outputChaptersUrl?: string;
    outputSubtitlesUrl?: string;
    durationMs?: number;
    fileSizeBytes?: number;
    resolution?: string;
    fps?: number;
  }
  ```

  This interface already exists and includes fileSizeBytes, so no changes needed.
  Just verify the completeJob() method properly stores all artifact fields.
  </action>
  <verify>Artifact fields stored correctly</verify>
  <done>Service supports all artifact metadata</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] R2 upload service compiles and can upload files
- [ ] AWS SDK installed for R2
- [ ] Thumbnail generator extracts frames from video
- [ ] Worker uploads video and thumbnail to R2
- [ ] Local files cleaned up after upload
- [ ] Job completed with R2 URLs in database
- [ ] TypeScript compiles without errors
- [ ] Environment variables documented
- [ ] End-to-end test: render → upload → cleanup → URLs stored
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Render worker uploads artifacts to R2
- Job stores R2 URLs instead of local paths
- Local files cleaned up automatically
- Thumbnail generated and uploaded
- Error handling for upload failures
- Ready for production use
</success_criteria>

<output>
After completion, create `.planning/phases/13-rendering-automation/13-03-SUMMARY.md`:

# Phase 13 Plan 3: Artifact Management & R2 Upload Summary

**Complete artifact pipeline with cloud storage**

## Accomplishments

- Built R2 upload service with AWS S3 SDK
- Created thumbnail generator using ffmpeg
- Integrated artifact upload into render worker
- Added local file cleanup after upload
- Documented R2 environment variables
- Complete end-to-end artifact pipeline

## Next Step

Phase 13 complete! Rendering automation fully operational.
</output>
