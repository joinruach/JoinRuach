---
phase: 10-transcript-alignment
plan: 01
type: execute
---

<objective>
Implement transcript alignment for multi-camera recording sessions using Phase 9 sync offsets.

Purpose: Enable accurate, camera-aligned transcripts for editing and caption generation. Leverage sync offsets from Phase 9 to generate aligned transcripts for all cameras from a single master transcription, minimizing API costs.

Output: Working transcription service with AssemblyAI integration, aligned transcripts stored in Strapi, and SRT/VTT generation capability.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/phases/09-media-ingestion-sync/09-RESEARCH.md
@.planning/phases/09-media-ingestion-sync/09-02-DECISIONS.md
@.planning/phases/10-transcript-alignment/10-RESEARCH.md
@ruach-ministries-backend/src/api/recording-session/content-types/recording-session/schema.json
@ruach-ministries-backend/src/services/sync-engine.ts
@ruach-ministries-backend/src/api/recording-session/services/sync-service.ts

**Phase 9 provides:**
- `syncOffsets_ms` - Camera time offsets (e.g., {A: 0, B: 1830, C: -420})
- `anchorAngle` - Master camera identifier
- `r2_audio_wav_url` - High-quality WAV audio for transcription
- `operatorStatus` - Sync approval status

**Standard stack (from research):**
- AssemblyAI for speech-to-text with word-level timestamps + speaker diarization
- subtitle.js for SRT/VTT generation
- JSON master format + derived SRT/VTT

**Don't hand-roll (from research):**
- Speech-to-text (use AssemblyAI)
- Speaker diarization (use API feature)
- Word-level timestamps (use API feature)
- Confidence scoring (use API feature)

**Common pitfalls to avoid:**
- Timestamp overflow/underflow from negative offsets → clamp to 0
- Transcribing all cameras separately → transcribe master only, apply offsets
- Not storing JSON master format → lose word-level data
- Ignoring low confidence segments → flag for manual review
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install AssemblyAI SDK and subtitle library</name>
  <files>ruach-ministries-backend/package.json</files>
  <action>Install AssemblyAI Node SDK and subtitle.js for transcript generation. Run: cd ruach-ministries-backend && pnpm add assemblyai subtitle. These are production dependencies, not dev dependencies.</action>
  <verify>pnpm list assemblyai subtitle shows both installed</verify>
  <done>assemblyai and subtitle packages in package.json dependencies</done>
</task>

<task type="auto">
  <name>Task 2: Create transcription service with AssemblyAI integration</name>
  <files>ruach-ministries-backend/src/services/transcription-service.ts</files>
  <action>Create service that:
  1. Accepts sessionId and optionally apiKey (from env if not provided)
  2. Loads session with assets and sync data from Phase 9
  3. Gets master camera audio URL (r2_audio_wav_url from asset where angle = anchorAngle)
  4. Calls AssemblyAI API with options: speaker_labels=true, language_code='en'
  5. Returns transcript with word-level timestamps and speaker labels
  6. Uses AssemblyAI SDK (import { AssemblyAI } from 'assemblyai')

  Key implementation details:
  - Initialize client: const client = new AssemblyAI({ apiKey })
  - Transcribe: await client.transcripts.transcribe({ audio_url, speaker_labels: true })
  - Check status: if (transcript.status === 'error') throw error
  - Extract words array with: word.text, word.start (ms), word.end (ms), word.confidence, word.speaker
  - Group words into segments by speaker (when speaker changes, start new segment)

  DON'T use jsonwebtoken or manual API calls - use the AssemblyAI SDK which handles auth and polling correctly.</action>
  <verify>TypeScript compiles without errors, service exports transcribeSession function</verify>
  <done>Service can load session, get master audio URL, call AssemblyAI API, return structured transcript</done>
</task>

<task type="auto">
  <name>Task 3: Create transcript alignment service</name>
  <files>ruach-ministries-backend/src/services/transcript-alignment-service.ts</files>
  <action>Create service that applies Phase 9 sync offsets to master transcript:
  1. Accepts master transcript segments (from Task 2) and syncOffsets from session
  2. For each camera in syncOffsets, creates aligned version:
     - Add camera offset to each segment.start and segment.end
     - Add camera offset to each word.start and word.end
     - Clamp all timestamps to Math.max(0, timestamp + offset) to prevent negatives
  3. Returns Record<string, TranscriptSegment[]> with aligned transcripts per camera

  TypeScript interfaces:
  - TranscriptSegment: { speaker: string; start: number; end: number; text: string; words: WordTimestamp[] }
  - WordTimestamp: { word: string; start: number; end: number; confidence: number; speaker?: string }

  This is simple millisecond arithmetic - no complex algorithms needed. The heavy lifting (transcription) is done by AssemblyAI.</action>
  <verify>TypeScript compiles, service exports alignTranscripts function</verify>
  <done>Service can apply offsets to all timestamps, handle negative offsets by clamping to 0</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] pnpm run build succeeds in ruach-ministries-backend
- [ ] No TypeScript errors
- [ ] assemblyai and subtitle packages installed
- [ ] transcription-service.ts exports transcribeSession function
- [ ] transcript-alignment-service.ts exports alignTranscripts function
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Services use Phase 9 sync offsets correctly
- Timestamps are properly aligned and clamped to prevent negatives
- Ready for Phase 10 Plan 2 (Strapi integration + SRT/VTT generation)
</success_criteria>

<output>
After completion, create `.planning/phases/10-transcript-alignment/10-01-SUMMARY.md`:

# Phase 10 Plan 1: Transcription & Alignment Services Summary

**AssemblyAI integration complete with sync offset alignment**

## Accomplishments

- Installed AssemblyAI SDK and subtitle.js
- Created transcription-service.ts for master camera transcription with speaker diarization
- Created transcript-alignment-service.ts for applying Phase 9 sync offsets
- Implemented timestamp clamping to prevent negative values from offset application

## Files Created/Modified

- `ruach-ministries-backend/package.json` - Added assemblyai, subtitle dependencies
- `ruach-ministries-backend/src/services/transcription-service.ts` - AssemblyAI integration
- `ruach-ministries-backend/src/services/transcript-alignment-service.ts` - Offset alignment logic

## Decisions Made

- Using AssemblyAI (not Deepgram or Whisper) for best speaker diarization quality
- Transcribe master camera only, apply offsets to generate aligned transcripts for all cameras
- Clamp timestamps to Math.max(0, value) to handle negative offsets from Phase 9

## Issues Encountered

[To be filled during execution]

## Next Step

Ready for 10-02-PLAN.md: Strapi integration, SRT/VTT generation, and API endpoints
</output>
